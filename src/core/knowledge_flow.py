"""
çŸ¥è¯†æµæ¨¡å—
KnowlEdgeæ ¸å¿ƒç±»ï¼Œæ•´åˆç”¨æˆ·ç”»åƒã€æœç´¢åŠŸèƒ½å’ŒæŠ¥å‘Šç”ŸæˆåŠŸèƒ½
"""
import logging
import asyncio
import json
import os
import sys
import re
import requests
from typing import Dict, List, Optional, Any, Tuple, AsyncIterator, Union

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.insert(0, project_root)

# ä¿®å¤å¯¼å…¥è·¯å¾„é—®é¢˜
try:
    # å½“åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ—¶
    from src.config import Config
    from src.utils import setup_logging
    from src.models.user_profile import UserProfileManager, EnhancedUserProfileExtractor
    from src.models.resume_reader import ResumeReader
    from src.core.search import (
        SearchEngine, 
        GoogleScholarSearch,
        ArxivSearch,
        PatentSearch,
        WebSearch,
        NewsSearch,
        SearchManager
    )
    from src.core.generators import ReportGenerator
    from src.core.llm_interface import LLMInterface
    from src.core.reference_formatter import ReferenceFormatter
except ImportError:
    # å½“åœ¨srcç›®å½•ä¸‹è¿è¡Œæ—¶
    from config import Config
    from utils import setup_logging
    from models.user_profile import UserProfileManager, EnhancedUserProfileExtractor
    from models.resume_reader import ResumeReader
    from core.search import (
        SearchEngine, 
        GoogleScholarSearch,
        ArxivSearch,
        PatentSearch,
        WebSearch,
        NewsSearch,
        SearchManager
    )
    from core.generators import ReportGenerator
    from core.llm_interface import LLMInterface
    from core.reference_formatter import ReferenceFormatter

# è®¾ç½®æ—¥å¿—
setup_logging()

class KnowledgeFlow:
    """çŸ¥è¯†æµç¨‹ç®¡ç†ç±»"""
    
    def __init__(self, config_path: Optional[str] = None, llm_model: Optional[str] = None):
        """åˆå§‹åŒ–çŸ¥è¯†æµç¨‹å®ä¾‹"""
        # åŠ è½½é…ç½®
        self.config = Config(config_path)
        
        # åˆå§‹åŒ–å„ç»„ä»¶
        self.llm = LLMInterface(model_override=llm_model)
        
        self.profile_manager = UserProfileManager()
        self.enhanced_profile_extractor = EnhancedUserProfileExtractor(self.llm)
        self.resume_reader = ResumeReader()
        self.search_engine = SearchEngine(self.config)
        self.report_generator = ReportGenerator(self.llm)
        self.search_manager = SearchManager()
        self.reference_formatter = ReferenceFormatter()
        
        # å¯ç”¨æœç´¢å¹³å°æ˜ å°„
        self.search_platforms = {
            "google_scholar": GoogleScholarSearch,
            "arxiv": ArxivSearch,
            "patent": PatentSearch,
            "web": WebSearch,
            "news": NewsSearch
        }
        
        # ç³»ç»ŸçŠ¶æ€
        self.is_initialized = True
        logging.info("KnowledgeFlowåˆå§‹åŒ–å®Œæˆ")
        
    async def get_or_create_user_profile(self, user_id: str, username: str = None) -> Dict:
        """è·å–æˆ–åˆ›å»ºç”¨æˆ·ç”»åƒ"""
        profile = self.profile_manager.get_user_profile(user_id)
        if not profile:
            logging.info(f"ä¸ºç”¨æˆ· {user_id} åˆ›å»ºæ–°ç”»åƒ")
            self.profile_manager.create_user_profile(user_id, username or f"ç”¨æˆ·_{user_id}")
            profile = self.profile_manager.get_user_profile(user_id)
        return profile
        
    async def update_user_interests(self, user_id: str, interests: List[str]) -> Dict:
        """æ›´æ–°ç”¨æˆ·å…´è¶£æ ‡ç­¾"""
        return self.profile_manager.update_user_interests(user_id, interests)
        
    async def analyze_resume(self, user_id: str, file_path: str) -> Dict:
        """åˆ†æç®€å†æ–‡ä»¶æ›´æ–°ç”¨æˆ·ç”»åƒï¼ˆä½¿ç”¨å¢å¼ºçš„æå–å™¨ï¼‰"""
        logging.info(f"å¼€å§‹ä¸ºç”¨æˆ· {user_id} åˆ†æç®€å†")
        
        # è¯»å–ç®€å†æ–‡æœ¬
        resume_text = self.resume_reader.read_resume(file_path)
        if not resume_text:
            return {"success": False, "message": "æ— æ³•è¯»å–ç®€å†æ–‡ä»¶"}
            
        # ä½¿ç”¨å¢å¼ºçš„ç®€å†åˆ†æ
        try:
            enhanced_profile = await self.enhanced_profile_extractor.extract_from_resume_with_enhancement(resume_text, user_id)
            if enhanced_profile:
                logging.info(f"å¢å¼ºç®€å†åˆ†æå®Œæˆï¼Œæå–åˆ°æŠ€èƒ½æ•°é‡: {len(enhanced_profile.get('enhanced_skills', []))}")
                
                # ä¿å­˜å¢å¼ºçš„æŠ€èƒ½ä¿¡æ¯åˆ°æ•°æ®åº“
                if 'enhanced_skills' in enhanced_profile:
                    self.profile_manager.update_user_profile(
                        user_id,
                        skills=enhanced_profile['enhanced_skills']
                    )
                    logging.info(f"å·²ä¿å­˜ {len(enhanced_profile['enhanced_skills'])} é¡¹å¢å¼ºæŠ€èƒ½")
                
                # æ³¨æ„ï¼šå…´è¶£å·²ç»åœ¨extract_from_resume_with_enhancementä¸­é€šè¿‡extract_interests_from_resumeä¿å­˜
                # ä¸éœ€è¦é‡å¤å¤„ç†ï¼Œé¿å…å åŠ é—®é¢˜
                
                return {"success": True, "message": "ç®€å†åˆ†æå®Œæˆ", "profile": enhanced_profile}
        except Exception as e:
            logging.error(f"å¢å¼ºç®€å†åˆ†æå¤±è´¥: {e}")
            
        # å›é€€åˆ°åŸå§‹LLMåˆ†æ
        system_msg = (
            "ä½ æ˜¯ä¸“ä¸šçš„ç®€å†åˆ†æå¸ˆã€‚è¯·åˆ†æç®€å†å†…å®¹ï¼Œæå–æŠ€èƒ½ä¿¡æ¯æ—¶éœ€è¦è¯„ä¼°æŠ€èƒ½ç­‰çº§ã€‚"
        )
        prompt = f"""
è¯·åˆ†æä¸‹åˆ—ç®€å†æ–‡æœ¬ï¼Œæå–ä¿¡æ¯å¹¶è¯„ä¼°æŠ€èƒ½ç­‰çº§ï¼ˆ1-10åˆ†ï¼Œä¿å®ˆè¯„åˆ†ï¼‰ï¼š

ç®€å†æ–‡æœ¬ï¼š
{resume_text}

è¯·è¿”å›JSONæ ¼å¼ï¼ŒåŒ…å«ï¼š
1. æ•™è‚²èƒŒæ™¯
2. å·¥ä½œç»å†  
3. æŠ€èƒ½åˆ—è¡¨ï¼ˆåŒ…å«æŠ€èƒ½åç§°ã€ç­‰çº§æè¿°ã€æ•°å€¼ç­‰çº§1-10ï¼‰
4. ç ”ç©¶å…´è¶£

JSONæ ¼å¼ï¼š
{{
  "education": [
    {{"institution": "", "major": "", "degree": "", "time": ""}}
  ],
  "work_experience": [
    {{"company": "", "position": "", "time": "", "description": ""}}
  ],
  "skills": [
    {{"skill": "æŠ€èƒ½åç§°", "level": "ç­‰çº§æè¿°", "skill_level": æ•°å€¼, "category": "ç±»åˆ«"}}
  ],
  "research_interests": [],
  "keywords": []
}}
"""
 
        try:
            def _strip_fences(s: str) -> str:
                t = s.strip()
                if t.startswith("```json"):
                    t = t[7:]
                if t.startswith("```"):
                    t = t[3:]
                if t.endswith("```"):
                    t = t[:-3]
                return t.strip()

            def _extract_json_fragment(s: str) -> Optional[str]:
                # ç²—ç•¥æå–ç¬¬ä¸€ä¸ªèŠ±æ‹¬å·æˆ–æ–¹æ‹¬å·åŒ…è£¹çš„JSONç‰‡æ®µ
                import re as _re
                for pattern in [r"\{[\s\S]*\}", r"\[[\s\S]*\]"]:
                    m = _re.search(pattern, s)
                    if m:
                        return m.group(0)
                return None

            result = await self.llm.call_llm(prompt, system_message=system_msg)
            cleaned = _strip_fences(result)
            try:
                parsed_result = json.loads(cleaned)
            except Exception:
                frag = _extract_json_fragment(cleaned)
                if not frag:
                    # è¿›è¡Œä¸€æ¬¡é‡è¯•ï¼Œè¯·æ±‚ä»…è¿”å›JSON
                    retry_prompt = (
                        "ä»…è¿”å›JSONï¼ˆæ— ä»»ä½•è§£é‡Šä¸å‰åç¼€ï¼‰ï¼Œå­—æ®µä¸º education, work_experience, skills, research_interests, keywordsã€‚\n"
                        "è‹¥ç¼ºå¤±ä¿¡æ¯è¯·ç»™ç©ºæ•°ç»„/ç©ºå­—ç¬¦ä¸²ã€‚\n\n"
                        f"ç®€å†æ–‡æœ¬ï¼š\n{resume_text}"
                    )
                    retry = await self.llm.call_llm(retry_prompt, system_message=system_msg)
                    cleaned_retry = _strip_fences(retry)
                    frag = _extract_json_fragment(cleaned_retry) or cleaned_retry
                parsed_result = json.loads(frag)
             
            # æå–å…´è¶£æ ‡ç­¾ - é¿å…å åŠ ï¼Œä½¿ç”¨æ–°çš„é€»è¾‘
            interests = []
            if "research_interests" in parsed_result:
                interests.extend(parsed_result["research_interests"])
            if "keywords" in parsed_result:
                interests.extend(parsed_result["keywords"])
             
            # æ›´æ–°ç”¨æˆ·ç”»åƒ
            self.profile_manager.update_user_profile(
                user_id,
                education=parsed_result.get("education", []),
                work_experience=parsed_result.get("work_experience", []),
                skills=parsed_result.get("skills", [])
            )
             
            # æ›´æ–°å…´è¶£æ ‡ç­¾ - ä½¿ç”¨æ–°çš„ä¸å åŠ é€»è¾‘
            if interests:
                # å»é‡å¹¶æ¸…æ´—
                uniq_interests = []
                seen = set()
                for it in interests:
                    if not isinstance(it, str):
                        continue
                    key = it.strip()
                    if key and key not in seen:
                        uniq_interests.append(key)
                        seen.add(key)
                if uniq_interests:
                    # ä½¿ç”¨æ–°çš„ä¸å åŠ æ›´æ–°é€»è¾‘
                    self.profile_manager.update_user_interests_from_resume(user_id, uniq_interests)
                 
            return {
                "success": True, 
                "profile": self.profile_manager.get_user_profile(user_id),
                "message": "ç®€å†åˆ†æå®Œæˆå¹¶æ›´æ–°ç”¨æˆ·ç”»åƒ"
            }
             
        except Exception as e:
            logging.error(f"ç®€å†åˆ†æå¤±è´¥: {str(e)}")
            return {"success": False, "message": f"ç®€å†åˆ†æå¤±è´¥: {str(e)}"}
            
    async def search_multiple_platforms(
        self, 
        query: str, 
        platforms: List[str], 
        user_id: Optional[str], 
        max_results: Union[int, Dict[str, int]],
        sort_by: str = "relevance",
        time_range: Optional[Dict] = None,
        categories: Optional[List] = None
    ) -> Dict:
        """åœ¨å¤šä¸ªå¹³å°ä¸Šæ‰§è¡Œæœç´¢ï¼ˆå¹¶å‘ï¼‰"""
        results: Dict[str, Any] = {}
        platform_engines = {
            "web": WebSearch(self.config),
            "arxiv": ArxivSearch(self.config),
            "google_scholar": GoogleScholarSearch(self.config),
            "patent": PatentSearch(self.config),
            "news": NewsSearch(self.config)
        }

        async def run_one(p: str):
            if p not in platform_engines:
                return p, {"error": f"ä¸æ”¯æŒçš„å¹³å°: {p}", "results": []}
            engine = platform_engines[p]
            try:
                platform_max = max_results[p] if isinstance(max_results, dict) else max_results
                if p == "arxiv":
                    data = await engine.search(query, platform_max, sort_by=sort_by, time_range=time_range, categories=categories)
                else:
                    data = await engine.search(query, platform_max)
                logging.info(f"{p} æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {data.get('result_count', len(data.get('results', [])))} æ¡ç»“æœ")
                return p, data
            except Exception as e:
                logging.error(f"{p} æœç´¢å¤±è´¥: {e}")
                return p, {"error": str(e), "query": query, "results": []}

        coros = [run_one(p) for p in platforms]
        done = await asyncio.gather(*coros)
        for p, data in done:
            results[p] = data

        if user_id:
            self.profile_manager.add_search_history(user_id, query, platforms)
        return results
        
    async def generate_report(
        self, 
        search_results: Dict, 
        user_input: Dict,
        report_type: str = "standard"
    ) -> str:
        """æ ¹æ®æœç´¢ç»“æœç”ŸæˆæŠ¥å‘Š"""
        logging.info(f"ç”ŸæˆæŠ¥å‘Šç±»å‹: {report_type}")
        
        original_query = user_input.get("query", "")
        
        if report_type == "literature_review":
            report = await self.report_generator.generate_literature_review(
                search_results, original_query
            )
        elif report_type == "corporate_research":
            report = await self.report_generator.generate_corporate_research_report(
                search_results, user_input, original_query
            )
        elif report_type == "popular_science":
            report = await self.report_generator.generate_popular_science_report(
                search_results, user_input, original_query
            )
        else:  # é»˜è®¤æ ‡å‡†æŠ¥å‘Š
            report = await self.report_generator.generate_report(search_results)
            
        return report
        
    async def generate_report_stream(
        self, 
        search_results: Dict, 
        user_input: Dict,
        report_type: str = "standard"
    ) -> AsyncIterator[str]:
        """æµå¼ç”ŸæˆæŠ¥å‘Š"""
        logging.info(f"æµå¼ç”ŸæˆæŠ¥å‘Šç±»å‹: {report_type}")
        
        original_query = user_input.get("query", "")
        
        if report_type == "literature_review":
            # ä½¿ç”¨å¢å¼ºç‰ˆæ–‡çŒ®ç»¼è¿°ç”Ÿæˆ
            async for chunk in self.report_generator.generate_enhanced_literature_review_stream(
                search_results, original_query
            ):
                yield chunk
        elif report_type == "corporate_research":
            async for chunk in self.report_generator.generate_corporate_research_report_stream(
                search_results, user_input, original_query
            ):
                yield chunk
        elif report_type == "popular_science":
            async for chunk in self.report_generator.generate_popular_science_report_stream(
                search_results, user_input, original_query
            ):
                yield chunk
        else:  # é»˜è®¤æ ‡å‡†æŠ¥å‘Š
            async for chunk in self.report_generator.generate_enhanced_standard_report_stream(search_results, user_input):
                yield chunk
    
    async def generate_enhanced_literature_review(self, query: str, platform: str = "arxiv", 
                                         num_results: int = 8) -> str:
        """
        ä½¿ç”¨å¤šæ¨¡å‹å¹¶è¡Œå¤„ç†ç”Ÿæˆå¢å¼ºç‰ˆæ–‡çŒ®ç»¼è¿°
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            platform: æœç´¢å¹³å°
            num_results: ç»“æœæ•°é‡
            
        Returns:
            ç”Ÿæˆçš„å¢å¼ºç‰ˆæ–‡çŒ®ç»¼è¿°
        """
        logging.info(f"ä½¿ç”¨å¤šæ¨¡å‹ç”Ÿæˆå¢å¼ºç‰ˆæ–‡çŒ®ç»¼è¿°: '{query}', å¹³å°: {platform}, ç»“æœæ•°é‡: {num_results}")
        
        # æ‰§è¡Œæœç´¢ï¼Œè·å–æ›´å¤šç»“æœç”¨äºæ–‡çŒ®ç»¼è¿°
        search_results = await self.search_manager.search(query, platform, num_results)
        
        # ä½¿ç”¨å¢å¼ºç‰ˆæ–‡çŒ®ç»¼è¿°ç”Ÿæˆå™¨
        report_chunks = []
        async for chunk in self.report_generator.generate_enhanced_literature_review_stream(search_results, query):
            report_chunks.append(chunk)
        
        return "".join(report_chunks)
        
    async def generate_enhanced_literature_review_stream(self, query: str, platform: str = "arxiv", 
                                               num_results: int = 8) -> AsyncIterator[str]:
        """
        æµå¼ç”Ÿæˆå¢å¼ºç‰ˆæ–‡çŒ®ç»¼è¿°
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            platform: æœç´¢å¹³å° 
            num_results: ç»“æœæ•°é‡
            
        Yields:
            æµå¼çš„æ–‡çŒ®ç»¼è¿°å†…å®¹
        """
        logging.info(f"æµå¼ç”Ÿæˆå¢å¼ºç‰ˆæ–‡çŒ®ç»¼è¿°: '{query}', å¹³å°: {platform}, ç»“æœæ•°é‡: {num_results}")
        
        # æ‰§è¡Œæœç´¢
        search_results = await self.search_manager.search(query, platform, num_results)
        
        # ç»Ÿè®¡æ£€ç´¢ç»“æœ
        found_count = 0
        for source, data in search_results.items():
            if isinstance(data, dict) and 'results' in data:
                found_count += len(data['results'])
        
        yield f"ğŸ” **æœç´¢å®Œæˆ**ï¼šåœ¨ {platform} å¹³å°æ£€ç´¢åˆ° {found_count} ç¯‡ç›¸å…³æ–‡çŒ®\n\n"
        yield "ğŸ“– **å¼€å§‹ç”Ÿæˆå¢å¼ºç‰ˆæ–‡çŒ®ç»¼è¿°**ï¼šç¡®ä¿æ‰€æœ‰æ–‡çŒ®éƒ½è¢«åˆ†æå¹¶ä¿æŒå†…å®¹ä¸€è‡´æ€§...\n\n"
        
        # ä½¿ç”¨å¢å¼ºç‰ˆç”Ÿæˆå™¨
        async for chunk in self.report_generator.generate_enhanced_literature_review_stream(search_results, query):
            yield chunk
        
    async def personalized_search(
        self, 
        user_id: str, 
        query: str, 
        platforms: List[str],
        max_results: Union[int, Dict[str, int]],
        sort_by: str = "relevance",
        time_range: Optional[Dict] = None,
        categories: Optional[List] = None
    ) -> Dict:
        """ä¸ªæ€§åŒ–æœç´¢ï¼šä¼˜åŒ–æŸ¥è¯¢å¹¶æ‰§è¡Œæœç´¢"""
        logging.info(f"è®°å½•ç”¨æˆ· {user_id} çš„æœç´¢: {query}")
        
        # åŸºäºæœç´¢å†…å®¹åˆ†æå’Œæ›´æ–°ç”¨æˆ·å…´è¶£å’ŒæŠ€èƒ½
        try:
            if user_id and query:
                # æå–å…´è¶£
                interests = self.enhanced_profile_extractor.extract_interests_from_search(query, user_id)
                if interests:
                    logging.info(f"ä¸ºç”¨æˆ· {user_id} æå–åˆ° {len(interests)} ä¸ªæœç´¢å…´è¶£: {[i.topic for i in interests]}")
                
                # æå–æŠ€èƒ½
                skills = self.enhanced_profile_extractor.extract_skills_from_search(query, user_id)
                if skills:
                    logging.info(f"ä¸ºç”¨æˆ· {user_id} æå–åˆ° {len(skills)} ä¸ªæœç´¢æŠ€èƒ½: {[s.skill for s in skills]}")
        except Exception as e:
            logging.error(f"ç”¨æˆ·ç”»åƒåˆ†æå¤±è´¥: {e}")
        
        profile = self.profile_manager.get_user_profile(user_id)
        
        # ä½¿ç”¨LLMä¼˜åŒ–æŸ¥è¯¢
        enhanced_query = await self._optimize_query(query, profile)
        
        # è¿™é‡Œç»Ÿä¸€ç”¨ enhanced_query æ‰§è¡Œå’Œè®°å½•
        logging.info(f"åœ¨å¹³å° {', '.join(platforms)} ä¸Šæœç´¢(å·²ä¼˜åŒ–): '{enhanced_query}'")
        search_results = await self.search_multiple_platforms(
            enhanced_query, platforms, user_id, max_results, sort_by, time_range, categories
        )
        
        return {
            "results": search_results,
            "original_query": query,
            "enhanced_query": enhanced_query,
            "sort_by": sort_by,
            "time_range": time_range,
            "categories": categories,
            "platform_type": ", ".join(platforms)
        }
        
    async def _optimize_query(self, query: str, profile: dict = None) -> str:
        """ä½¿ç”¨LLMä¼˜åŒ–æŸ¥è¯¢ï¼Œä½¿å…¶æ›´é€‚åˆå­¦æœ¯æœç´¢"""
        # æ£€æµ‹æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
        if re.search(r'[\u4e00-\u9fff]', query):
            # å¦‚æœæŸ¥è¯¢æ˜¯å¯¹è¯å¼è¯·æ±‚ï¼Œè½¬æ¢ä¸ºé€‚åˆå­¦æœ¯æœç´¢çš„å½¢å¼
            if any(phrase in query.lower() for phrase in [
                "å¸®æˆ‘", "è¯·", "æˆ‘æƒ³", "èƒ½å¦", "å¯ä»¥", "å¸Œæœ›", "éº»çƒ¦", "å‘Šè¯‰æˆ‘", "è·Ÿè¸ª"
            ]):
                prompt = f"""
                è¯·å°†ä»¥ä¸‹å¯¹è¯å¼æŸ¥è¯¢ç¿»è¯‘ä¸ºç®€æ´çš„è‹±æ–‡å­¦æœ¯æœç´¢å…³é”®è¯ï¼Œä¿ç•™æ ¸å¿ƒä¸»é¢˜å’Œæ¦‚å¿µï¼Œå»é™¤å¯¹è¯æ€§è´¨çš„è¯è¯­ã€‚
                æŸ¥è¯¢: {query}
                åªè¿”å›è½¬æ¢åçš„è‹±æ–‡å…³é”®è¯ã€‚
                """
                try:
                    enhanced_query = await self.llm.call_llm(prompt)
                    enhanced_query = enhanced_query.strip('" \n\t')
                    if re.search(r'[\u4e00-\u9fff]', enhanced_query):
                        enhanced_query = await self._traditional_translate(query)
                    return enhanced_query
                except Exception:
                    return await self._traditional_translate(query)
            else:
                return await self._traditional_translate(query)
        return query
        
    async def _traditional_translate(self, text: str, source_lang="zh-CN", target_lang="en") -> str:
        """ä½¿ç”¨ä¼ ç»Ÿç¿»è¯‘APIç¿»è¯‘æ–‡æœ¬"""
        try:
            translate_api_url = "https://translate.googleapis.com/translate_a/single"
            params = {
                "client": "gtx",
                "sl": source_lang,
                "tl": target_lang,
                "dt": "t",
                "q": text
            }
            response = await asyncio.to_thread(
                requests.get, 
                translate_api_url, 
                params=params, 
                timeout=5
            )
            if response.status_code == 200:
                result = response.json()
                if result and isinstance(result, list) and len(result) > 0:
                    translations = []
                    for sentence in result[0]:
                        if sentence and isinstance(sentence, list) and len(sentence) > 0:
                            translations.append(sentence[0])
                    translated = " ".join(translations)
                    logging.info(f"ä¼ ç»ŸAPIç¿»è¯‘: '{text}' -> '{translated}'")
                    return translated
            return self._simple_translate(text)
        except Exception as e:
            logging.error(f"ä¼ ç»Ÿç¿»è¯‘APIè°ƒç”¨å¤±è´¥: {e}")
            return self._simple_translate(text)
        
    def _simple_translate(self, query: str) -> str:
        """ç®€å•çš„ä¸­æ–‡å…³é”®è¯æ˜ å°„"""
        translations = {
            "æ·±åº¦å­¦ä¹ ": "deep learning",
            "æœºå™¨å­¦ä¹ ": "machine learning",
            "äººå·¥æ™ºèƒ½": "artificial intelligence",
            "ç¥ç»ç½‘ç»œ": "neural network",
            "å·ç§¯ç¥ç»ç½‘ç»œ": "convolutional neural network CNN",
            "è‡ªç„¶è¯­è¨€å¤„ç†": "natural language processing NLP",
            "è®¡ç®—æœºè§†è§‰": "computer vision",
            "å¼ºåŒ–å­¦ä¹ ": "reinforcement learning",
            "ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ": "generative adversarial network GAN",
            "è¿ç§»å­¦ä¹ ": "transfer learning",
            "æ³¨æ„åŠ›æœºåˆ¶": "attention mechanism",
            "å›¾ç¥ç»ç½‘ç»œ": "graph neural network",
            "çŸ¥è¯†å›¾è°±": "knowledge graph",
            "è¯­ä¹‰åˆ†å‰²": "semantic segmentation",
            "ç›®æ ‡æ£€æµ‹": "object detection",
            "å›¾åƒåˆ†ç±»": "image classification",
            "è¯­éŸ³è¯†åˆ«": "speech recognition",
            "æ¨èç³»ç»Ÿ": "recommendation system",
            "æƒ…æ„Ÿåˆ†æ": "sentiment analysis",
            "èšç±»": "clustering",
            "åˆ†ç±»": "classification",
            "å›å½’": "regression",
            "ä¼˜åŒ–": "optimization",
            "åŒ»å­¦å½±åƒ": "medical imaging",
            "è‡ªåŠ¨é©¾é©¶": "autonomous driving",
            "å¤§è¯­è¨€æ¨¡å‹": "large language model LLM",
            "å˜æ¢å™¨": "transformer",
            "é¢„è®­ç»ƒ": "pre-training",
            "å¾®è°ƒ": "fine-tuning",
            "åµŒå…¥": "embedding",
            "å‘é‡åŒ–": "vectorization",
            "å¤šæ¨¡æ€": "multimodal",
            "æ•°æ®å¢å¼º": "data augmentation",
            "è¿‡æ‹Ÿåˆ": "overfitting",
            "æ­£åˆ™åŒ–": "regularization"
        }
        translated_query = query
        for zh, en in translations.items():
            if zh in query:
                translated_query = translated_query.replace(zh, en)
        if translated_query == query:
            english_terms = re.findall(r'[a-zA-Z0-9]+(?:\s+[a-zA-Z0-9]+)*', query)
            if english_terms:
                return " ".join(english_terms)
            else:
                return "recent research papers"
        logging.info(f"ç®€å•æ˜ å°„ç¿»è¯‘: '{query}' -> '{translated_query}'")
        return translated_query

    async def generate_literature_review_stream(
        self, 
        search_results: Dict, 
        original_query: str
    ) -> AsyncIterator[str]:
        """æµå¼ç”Ÿæˆæ–‡çŒ®ç»¼è¿°"""
        logging.info(f"æµå¼ç”Ÿæˆæ–‡çŒ®ç»¼è¿°: {original_query}")
        async for chunk in self.report_generator.generate_literature_review_stream(
            search_results, original_query
        ):
            yield chunk

    async def generate_corporate_research_report_stream(
        self, 
        search_results: Dict,
        user_input: Dict,
        original_query: str
    ) -> AsyncIterator[str]:
        """æµå¼ç”Ÿæˆä¼ä¸šè°ƒç ”æŠ¥å‘Š"""
        logging.info(f"æµå¼ç”Ÿæˆä¼ä¸šè°ƒç ”æŠ¥å‘Š: {original_query}")
        async for chunk in self.report_generator.generate_corporate_research_report_stream(
            search_results, user_input, original_query
        ):
            yield chunk

    async def generate_popular_science_report_stream(
        self, 
        search_results: Dict,
        user_input: Dict,
        original_query: str
    ) -> AsyncIterator[str]:
        """æµå¼ç”Ÿæˆç§‘æ™®çŸ¥è¯†æŠ¥å‘Š"""
        logging.info(f"æµå¼ç”Ÿæˆç§‘æ™®çŸ¥è¯†æŠ¥å‘Š: {original_query}")
        async for chunk in self.report_generator.generate_popular_science_report_stream(
            search_results, user_input, original_query
        ):
            yield chunk

    async def process_query(self, query: str, platform: str = "arxiv", 
                     num_results: int = 5, report_type: str = "standard") -> str:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼Œæ‰§è¡Œæœç´¢å¹¶ç”ŸæˆæŠ¥å‘Š
        """
        logging.info(f"å¤„ç†æŸ¥è¯¢: '{query}', å¹³å°: {platform}, ç»“æœæ•°é‡: {num_results}, æŠ¥å‘Šç±»å‹: {report_type}")
        
        search_results = await self.search_manager.search(query, platform, num_results)
        
        references = self.reference_formatter.extract_references(search_results)
        logging.info(f"æå–åˆ° {len(references)} æ¡å‚è€ƒæ–‡çŒ®")
        
        if report_type == "literature_review":
            report = await self.report_generator.generate_literature_review(search_results, query)
        elif report_type == "corporate_research":
            report = await self.report_generator.generate_corporate_research_report(search_results, {"query": query}, query)
        elif report_type == "popular_science":
            report = await self.report_generator.generate_popular_science_report(search_results, {"query": query}, query)
        else:
            report = await self.report_generator.generate_report(search_results)
        return report
        
    async def process_query_stream(self, query: str, platform: str = "arxiv", 
                           num_results: int = 5, report_type: str = "standard") -> AsyncIterator[str]:
        """
        æµå¼å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼Œæ‰§è¡Œæœç´¢å¹¶ç”ŸæˆæŠ¥å‘Š
        """
        logging.info(f"æµå¼å¤„ç†æŸ¥è¯¢: '{query}', å¹³å°: {platform}, ç»“æœæ•°é‡: {num_results}, æŠ¥å‘Šç±»å‹: {report_type}")
        
        yield f"æ­£åœ¨æœç´¢ '{query}'ï¼Œå¹³å°: {platform}ï¼Œè¯·ç¨å€™...\n\n"
        
        search_results = await self.search_manager.search(query, platform, num_results)
        
        found_count = 0
        for source, data in search_results.items():
            if isinstance(data, dict) and 'results' in data:
                found_count += len(data['results'])
        
        yield f"å·²æ‰¾åˆ° {found_count} æ¡ç›¸å…³ç»“æœï¼Œæ­£åœ¨ç”ŸæˆæŠ¥å‘Š...\n\n"
        
        user_input = {"query": query}
        if report_type == "literature_review":
            async for chunk in self.report_generator.generate_literature_review_stream(search_results, query):
                yield chunk
        elif report_type == "corporate_research":
            async for chunk in self.report_generator.generate_corporate_research_report_stream(search_results, user_input, query):
                yield chunk
        elif report_type == "popular_science":
            async for chunk in self.report_generator.generate_popular_science_report_stream(search_results, user_input, query):
                yield chunk
        else:
            async for chunk in self.report_generator.generate_report_stream(search_results, user_input):
                yield chunk
    
    async def generate_enhanced_literature_review(self, query: str, platform: str = "arxiv", 
                                         num_results: int = 8) -> str:
        """
        ä½¿ç”¨å¤šæ¨¡å‹å¹¶è¡Œå¤„ç†ç”Ÿæˆå¢å¼ºç‰ˆæ–‡çŒ®ç»¼è¿°
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            platform: æœç´¢å¹³å°
            num_results: ç»“æœæ•°é‡
            
        Returns:
            ç”Ÿæˆçš„å¢å¼ºç‰ˆæ–‡çŒ®ç»¼è¿°
        """
        logging.info(f"ä½¿ç”¨å¤šæ¨¡å‹ç”Ÿæˆå¢å¼ºç‰ˆæ–‡çŒ®ç»¼è¿°: '{query}', å¹³å°: {platform}, ç»“æœæ•°é‡: {num_results}")
        
        # æ‰§è¡Œæœç´¢ï¼Œè·å–æ›´å¤šç»“æœç”¨äºæ–‡çŒ®ç»¼è¿°
        search_results = await self.search_manager.search(query, platform, num_results)
        
        # ä½¿ç”¨å¢å¼ºç‰ˆæ–‡çŒ®ç»¼è¿°ç”Ÿæˆå™¨
        report_chunks = []
        async for chunk in self.report_generator.generate_enhanced_literature_review_stream(search_results, query):
            report_chunks.append(chunk)
        
        return "".join(report_chunks)
        
    async def generate_enhanced_literature_review_stream(self, query: str, platform: str = "arxiv", 
                                               num_results: int = 8) -> AsyncIterator[str]:
        """
        æµå¼ç”Ÿæˆå¢å¼ºç‰ˆæ–‡çŒ®ç»¼è¿°
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            platform: æœç´¢å¹³å° 
            num_results: ç»“æœæ•°é‡
            
        Yields:
            æµå¼çš„æ–‡çŒ®ç»¼è¿°å†…å®¹
        """
        logging.info(f"æµå¼ç”Ÿæˆå¢å¼ºç‰ˆæ–‡çŒ®ç»¼è¿°: '{query}', å¹³å°: {platform}, ç»“æœæ•°é‡: {num_results}")
        
        # æ‰§è¡Œæœç´¢
        search_results = await self.search_manager.search(query, platform, num_results)
        
        # ç»Ÿè®¡æ£€ç´¢ç»“æœ
        found_count = 0
        for source, data in search_results.items():
            if isinstance(data, dict) and 'results' in data:
                found_count += len(data['results'])
        
        yield f"ğŸ” **æœç´¢å®Œæˆ**ï¼šåœ¨ {platform} å¹³å°æ£€ç´¢åˆ° {found_count} ç¯‡ç›¸å…³æ–‡çŒ®\n\n"
        yield "ğŸ“– **å¼€å§‹ç”Ÿæˆå¢å¼ºç‰ˆæ–‡çŒ®ç»¼è¿°**ï¼šç¡®ä¿æ‰€æœ‰æ–‡çŒ®éƒ½è¢«åˆ†æå¹¶ä¿æŒå†…å®¹ä¸€è‡´æ€§...\n\n"
        
        # ä½¿ç”¨å¢å¼ºç‰ˆç”Ÿæˆå™¨
        async for chunk in self.report_generator.generate_enhanced_literature_review_stream(search_results, query):
            yield chunk 